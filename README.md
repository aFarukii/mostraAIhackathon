# Mobility Data Analysis Scripts

Bu proje, mobil cihaz konum verilerini analiz ederek kullanÄ±cÄ±larÄ±n kahveci ve veteriner kliniklerine ziyaretlerini tespit eden Python scriptlerini iÃ§ermektedir. Spatial indexing ve machine learning teknikleri kullanÄ±larak bÃ¼yÃ¼k veri setleri Ã¼zerinde hÄ±zlÄ± ve etkili analizler yapÄ±lmaktadÄ±r.

## ğŸ“‹ Ä°Ã§indekiler

- [Gereksinimler](#gereksinimler)
- [Kurulum](#kurulum)
- [Scriptler](#scriptler)
  - [1. getunique_ids.py](#1-getunique_idspy)
  - [2. getLocationsbyID.py](#2-getlocationsbyidpy)
  - [3. matcher.py](#3-matcherpy)
  - [4. cofee_visits.py](#4-cofee_visitspy)
  - [5. vet_visiter.py](#5-vet_visiterpy)
  - [6. merger.py](#6-mergerpy)
- [Veri FormatlarÄ±](#veri-formatlarÄ±)
- [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
- [Performans ve Optimizasyon](#performans-ve-optimizasyon)

## ğŸ”§ Gereksinimler

```bash
pandas>=1.5.0
numpy>=1.21.0
scikit-learn>=1.0.0
pyarrow>=10.0.0
tqdm>=4.60.0
```

## ğŸ“¦ Kurulum

```bash
# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin
pip install pandas numpy scikit-learn pyarrow tqdm

# Projeyi klonlayÄ±n
git clone [repository-url]
cd mobility-data-analysis
```

## ğŸ“Š Scriptler

### 1. getunique_ids.py

**AmaÃ§:** Parquet dosyasÄ±ndan benzersiz cihaz ID'lerini Ã§Ä±karÄ±r ve CSV formatÄ±nda kaydeder.

**Ã–zellikler:**
- BÃ¼yÃ¼k parquet dosyalarÄ±nÄ± batch'ler halinde iÅŸler
- Memory-efficient okuma
- Benzersiz device_aid deÄŸerlerini toplar

**KullanÄ±m:**
```bash
python getunique_ids.py
```

**Girdi:**
- `MobilityDataMay2024.paraquet` - Ana mobility veri dosyasÄ±

**Ã‡Ä±ktÄ±:**
- `unique_device_ids.csv` - Benzersiz cihaz ID'leri listesi

**Kod YapÄ±sÄ±:**
```python
# Ana parquet dosyasÄ±nÄ± okur
dataset = ds.dataset(parafilepath, format="parquet")
scanner = dataset.scanner(batch_size=100_000)

# Her batch'i iÅŸleyerek unique ID'leri toplar
for record_batch in scanner.to_batches():
    df_chunk = record_batch.to_pandas()
    unique_ids.update(df_chunk["device_aid"].dropna().unique())
```

---

### 2. getLocationsbyID.py

**AmaÃ§:** Belirli cihaz ID'leri iÃ§in konum verilerini Ã§Ä±karÄ±r ve her cihaz iÃ§in ayrÄ± CSV dosyasÄ± oluÅŸturur.

**Ã–zellikler:**
- Hedef cihaz ID'lerini filtreler
- Her cihaz iÃ§in ayrÄ± dosya oluÅŸturur
- Batch processing ile memory optimization
- Ä°lerleme takibi

**KullanÄ±m:**
```bash
python getLocationsbyID.py
```

**Girdi:**
- `MobilityDataMay2024.paraquet` - Ana mobility veri dosyasÄ±
- `unique_device_ids.csv` - Hedef cihaz ID'leri

**Ã‡Ä±ktÄ±:**
- `{device_id}_data.csv` - Her cihaz iÃ§in ayrÄ± konum veri dosyasÄ±

**Algoritma:**
1. Hedef device_id'leri yÃ¼kler
2. Parquet dosyasÄ±nÄ± batch'ler halinde okur
3. Her batch'i filtreler
4. Cihaz bazÄ±nda gruplar
5. Her cihaz iÃ§in ayrÄ± CSV oluÅŸturur

---

### 3. matcher.py

**AmaÃ§:** BallTree algoritmasÄ± kullanarak cihaz konumlarÄ± ile mekan koordinatlarÄ±nÄ± eÅŸleÅŸtirir.

**Ã–zellikler:**
- Spatial indexing ile hÄ±zlÄ± konum eÅŸleÅŸtirme
- Haversine distance metriÄŸi
- Configurable distance threshold
- Toplu dosya iÅŸleme

**KullanÄ±m:**
```python
from matcher import toplu_eslestirme

toplu_eslestirme(
    mekanlar_dosyasi="clean_places.csv",
    devices_klasoru="devices",
    cikti_dosyasi="eslesmeler.csv",
    esik_metre=30
)
```

**Algoritma DetaylarÄ±:**
```python
def balltree_eslestirme(hareketler_df, mekanlar_df, esik_metre=50):
    # KoordinatlarÄ± radyana Ã§evir
    mekan_coords = np.radians(mekanlar_df[['lat', 'lng']].values)
    hareket_coords = np.radians(hareketler_df[['latitude', 'longitude']].values)
    
    # BallTree oluÅŸtur
    tree = BallTree(mekan_coords, metric='haversine')
    
    # YakÄ±n mekanlarÄ± bul
    indices, distances = tree.query_radius(hareket_coords, r=esik_radyan, return_distance=True)
```

**Performans:**
- O(log n) arama kompleksitesi
- Binlerce noktayÄ± saniyeler iÃ§inde iÅŸler
- Memory-efficient spatial indexing

---

### 4. cofee_visits.py

**AmaÃ§:** KullanÄ±cÄ±larÄ±n kahveci ziyaretlerini tespit eder ve analiz eder.

**Ã–zellikler:**
- 100 metre yarÄ±Ã§apÄ±nda kahveci tespiti
- Zaman damgasÄ± dÃ¶nÃ¼ÅŸtÃ¼rme (UTC â†’ GMT+3)
- Cihaz bazÄ±nda ziyaret sayÄ±sÄ± hesaplama
- BallTree ile hÄ±zlÄ± spatial analysis

**KullanÄ±m:**
```bash
python cofee_visits.py
```

**Girdi:**
- `devices/*.csv` - Cihaz konum dosyalarÄ±
- `kahveci2.csv` - Kahveci koordinatlarÄ± (name, lat, lng)

**Ã‡Ä±ktÄ±:**
- `coffee_visits_balltree.csv` - Cihaz bazÄ±nda kahveci ziyaret sayÄ±larÄ±

**Analiz SÃ¼reci:**
1. TÃ¼m cihaz verilerini birleÅŸtirir
2. Kahveci koordinatlarÄ±nÄ± yÃ¼kler
3. BallTree ile 100m yarÄ±Ã§apÄ±nda eÅŸleÅŸtirme
4. Cihaz baÅŸÄ±na ziyaret sayÄ±sÄ± hesaplama

**Veri Ä°ÅŸleme:**
```python
# Timestamp dÃ¶nÃ¼ÅŸtÃ¼rme
df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', utc=True).dt.tz_convert('Etc/GMT-3')

# BallTree ile yakÄ±nlÄ±k analizi
RADIUS_KM = 0.1  # 100 metre
tree = BallTree(coffee_coords, metric='haversine')
indices = tree.query_radius(user_coords, r=RADIUS_KM / EARTH_RADIUS_KM)
```

---

### 5. vet_visiter.py

**AmaÃ§:** KullanÄ±cÄ±larÄ±n veteriner klinikleri ziyaretlerini kapsamlÄ± analiz eder.

**Ã–zellikler:**
- 20 metre hassasiyetle veteriner tespiti
- DetaylÄ± zaman analizi (saatlik, gÃ¼nlÃ¼k)
- Veteriner bazÄ±nda popÃ¼lerlik analizi
- Ã‡oklu Ã§Ä±ktÄ± dosyasÄ±
- Comprehensive error handling

**KullanÄ±m:**
```bash
python vet_visiter.py
```

**Girdi:**
- `devices/*.csv` - Cihaz konum dosyalarÄ±
- `veterinerlerson.csv` - Veteriner koordinatlarÄ±

**Ã‡Ä±ktÄ±:**
- `vet_visits_balltree.csv` - Cihaz bazÄ±nda veteriner ziyaretleri
- `veteriner_detailed_analysis.csv` - Veteriner bazÄ±nda detaylÄ± analiz
- `veteriner_analysis_summary.csv` - Genel Ã¶zet istatistikleri

**Analiz BoyutlarÄ±:**
```python
# Her veteriner iÃ§in analiz
vet_analysis = {
    'total_visits': total_visits,
    'unique_visitors': unique_devices,
    'avg_visits_per_visitor': total_visits / unique_devices,
    'peak_hour': visits_by_hour.idxmax(),
    'peak_day': visits_by_day.idxmax(),
    'visits_per_day': total_visits / date_range_days
}
```

**Ä°statistiksel Ã‡Ä±ktÄ±lar:**
- Toplam ziyaret sayÄ±sÄ±
- Benzersiz ziyaretÃ§i sayÄ±sÄ±
- En yoÄŸun saat/gÃ¼n analizi
- PopÃ¼lerlik sÄ±ralamasÄ±
- Zaman serisi analizi

---

### 6. merger.py

**AmaÃ§:** FarklÄ± analizlerden gelen sonuÃ§larÄ± birleÅŸtirir ve master dataset oluÅŸturur.

**Ã–zellikler:**
- Multiple dataset merging
- Left join stratejisi
- Column name conflict resolution
- Data quality checks

**KullanÄ±m:**
```bash
python merger.py
```

**BirleÅŸtirilen Veri Setleri:**
- `coffee_visits_balltree.csv` - Kahveci ziyaret verileri
- `venue_analysis_results.csv` - Mekan puanlama verileri
- `kullanici_profilleri_fast.csv` - KapsamlÄ± ziyaret profilleri
- `vet_visits_balltree.csv` - Veteriner ziyaret verileri

**Ã‡Ä±ktÄ±:**
- `merged_dataset.csv` - BirleÅŸtirilmiÅŸ master dataset

**Merge Stratejisi:**
```python
# SÄ±ralÄ± left join iÅŸlemleri
merged_df = df2  # Base dataset
merged_df = merged_df.merge(df1, on='device_aid', how='left')
merged_df = merged_df.merge(df3, on='device_aid', how='left')
merged_df = merged_df.merge(df4, on='device_aid', how='left')

# Column name conflict resolution
if 'avg_visits_per_day_x' in merged_df.columns:
    merged_df = merged_df.rename(columns={
        'avg_visits_per_day_x': 'coffee_avg_visits_per_day',
        'avg_visits_per_day_y': 'vet_avg_visits_per_day'
    })
```

## ğŸ“ Veri FormatlarÄ±

### Girdi Veri FormatlarÄ±

**Mobility Data (Parquet/CSV):**
```
device_aid,timestamp,latitude,longitude
ABC123,1684567890,41.0082,28.9784
DEF456,1684567920,41.0085,28.9787
```

**Coffee Shops (kahveci2.csv):**
```
name,lat,lng
Starbucks Taksim,41.0370,28.9857
Kahve DÃ¼nyasÄ± KadÄ±kÃ¶y,40.9903,29.0275
```

**Veterinary Clinics (veterinerlerson.csv):**
```
name,latitude,longitude
Pet Vet Clinic,41.0123,28.9654
Animal Hospital KadÄ±kÃ¶y,40.9876,29.0123
```

### Ã‡Ä±ktÄ± Veri FormatlarÄ±

**Coffee Visits:**
```
device_aid,coffee_visit_count
ABC123,5
DEF456,12
```

**Veterinary Analysis:**
```
veteriner_name,total_visits,unique_visitors,peak_hour,peak_day
Pet Vet Clinic,45,12,14,Monday
Animal Hospital,67,23,16,Wednesday
```

## ğŸš€ KullanÄ±m Ã–rnekleri

### Tam Analiz Pipeline

```bash
# 1. Benzersiz ID'leri Ã§Ä±kar
python getunique_ids.py

# 2. Cihaz verilerini ayÄ±r
python getLocationsbyID.py

# 3. Kahveci analizini Ã§alÄ±ÅŸtÄ±r
python cofee_visits.py

# 4. Veteriner analizini Ã§alÄ±ÅŸtÄ±r
python vet_visiter.py

# 5. TÃ¼m sonuÃ§larÄ± birleÅŸtir
python merger.py
```

### Ã–zelleÅŸtirilmiÅŸ Analiz

```python
# Mesafe threshold'unu deÄŸiÅŸtir
# cofee_visits.py iÃ§inde:
RADIUS_KM = 0.05  # 50 metre

# vet_visiter.py iÃ§inde:
RADIUS_KM = 0.03  # 30 metre
```

## âš¡ Performans ve Optimizasyon

### Memory Optimization
- Batch processing ile memory kullanÄ±mÄ±nÄ± kontrol eder
- Chunk-based okuma ile bÃ¼yÃ¼k dosyalarÄ± iÅŸler
- Garbage collection ile bellek temizliÄŸi

### Spatial Indexing
- BallTree algoritmasÄ± O(log n) complexity
- Haversine distance metric iÃ§in optimize edilmiÅŸ
- Vectorized operations ile hÄ±zlandÄ±rÄ±lmÄ±ÅŸ

### Processing Speed
- Parallel processing capabilities
- Optimized pandas operations
- Efficient coordinate transformations

### Ã–rnek Performans Metrikleri:
- 1M konum noktasÄ±: ~30 saniye
- 10K mekan noktasÄ±: ~2 saniye
- Memory usage: ~500MB peak

## ğŸ› Troubleshooting

### YaygÄ±n Hatalar

1. **FileNotFoundError**: Girdi dosyalarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol edin
2. **MemoryError**: Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n
3. **KeyError**: CSV column isimlerini kontrol edin
4. **Coordinate Issues**: Lat/lng deÄŸerlerinin geÃ§erliliÄŸini kontrol edin

### Debug Modu
```python
# Verbose output iÃ§in
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ¤ KatkÄ±da Bulunma

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“ Ä°letiÅŸim

Herhangi bir sorunuz iÃ§in issue aÃ§abilir veya [maintainer-email] adresinden iletiÅŸime geÃ§ebilirsiniz.
